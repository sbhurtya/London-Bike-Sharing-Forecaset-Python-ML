{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import optuna\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pmdarima import auto_arima\n",
    "import os\n",
    "import holidays\n",
    "\n",
    "\n",
    "#Save requirements\n",
    "os.system(\"pip freeze > requirements.txt\")\n",
    "\n",
    "#SEED   \n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/london_merged.csv')\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Metadata:\n",
    "  - \"timestamp\" - timestamp field for grouping the data\n",
    "  - \"cnt\" - the count of a new bike shares\n",
    "  - \"t1\" - real temperature in C\n",
    "  - \"t2\" - temperature in C \"feels like\"\n",
    "  - \"hum\" - humidity in percentage\n",
    "  - \"wind_speed\" - wind speed in km/h\n",
    "  - \"weather_code\" - category of the weather\n",
    "  - \"is_holiday\" - boolean field - 1 holiday / 0 non holiday\n",
    "  - \"is_weekend\" - boolean field - 1 if the day is weekend\n",
    "  - \"season\" - category field meteorological seasons: 0-spring ; 1-summer; 2-fall; 3-winter.\n",
    "  - \"weathe_code\" category description:\n",
    "     - 1 = Clear ; mostly clear but have some values with haze/fog/patches of fog/ fog in vicinity \n",
    "     - 2 = scattered clouds / few clouds \n",
    "     - 3 = Broken clouds \n",
    "     - 4 = Cloudy \n",
    "     - 7 = Rain/ light Rain shower/ Light rain \n",
    "     - 10 = rain with thunderstorm \n",
    "     - 26 = snowfall \n",
    "     - 94 = Freezing Fog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "#Keep records from 2015 and 2016\n",
    "df = df[(df['timestamp'].dt.year == 2015) | (df['timestamp'].dt.year == 2016)]\n",
    "#Sort the values by timestamp\n",
    "df = df.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No missing values. But there might be missing timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing timestamps\n",
    "all_days = pd.date_range(start=df['timestamp'].min(), end=df['timestamp'].max(), freq='h')\n",
    "missing_days = all_days[~all_days.isin(df['timestamp'])]\n",
    "print('Number of missing timestamps:', len(missing_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_days[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 130 timestamps are missing. We will imput them using existing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#London holidays\n",
    "uk_holidays = holidays.UK(years=[df['timestamp'].dt.year.min(), df['timestamp'].dt.year.max()])\n",
    "uk_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataframe using all days\n",
    "df_full = pd.DataFrame(all_days, columns=['timestamp'])\n",
    "#Merge with df to get cnt, t1, t2, hum, wind_speed, weather_code, season\n",
    "df_full = df_full.merge(df[['timestamp', 'cnt', 't1', 't2', 'hum', 'wind_speed', 'weather_code', 'season']], on='timestamp', how='left')\n",
    "#is_holiday column: 1 if holiday, 0 if not\n",
    "df_full['is_holiday'] = np.where(df_full['timestamp'].dt.date.isin(uk_holidays), 1, 0)\n",
    "df_full['is_weekend'] = np.where(df_full['timestamp'].dt.dayofweek.isin([5, 6]), 1, 0)\n",
    "\n",
    "#Backfill missing values\n",
    "df_full = df_full.ffill()\n",
    "df = df_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_days = all_days[~all_days.isin(df['timestamp'])]\n",
    "print('Number of missing timestamps:', len(missing_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the timestamp as the index\n",
    "df.set_index('timestamp', inplace=True)\n",
    "#Set period to 1 hour\n",
    "df.index = pd.DatetimeIndex(df.index).to_period('h')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.resample('D').agg({'cnt':'sum', \n",
    "                           't1':'median', \n",
    "                           't2':'median', \n",
    "                           'hum':'median', \n",
    "                           'wind_speed':'median', \n",
    "                           'weather_code': lambda x: x.value_counts().index[0], \n",
    "                           'season': lambda x: x.value_counts().index[0], \n",
    "                           'is_holiday':'max', \n",
    "                           'is_weekend':'max'})\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Boxplot of all the columns\n",
    "plt.figure(figsize=(10, 12))\n",
    "cols = df.columns\n",
    "print(cols)\n",
    "for i in range(1, len(cols)):\n",
    "    print(cols[i])\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(df[cols[i-1]])\n",
    "    plt.title(cols[i-1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is no abnormal data in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Real and feels like temperature are highly correlated. Let's use feels like temperature since it is more likely to impact the decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop t1\n",
    "df.drop('t1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map codes\n",
    "#Map weather code:\n",
    "weather_desc = {\n",
    "    1: 'Clear', 2: 'Scattered_Clouds', 3: 'Broken_Clouds', 4: 'Cloudy', 7: 'Rain', 10: 'Storm', 26: 'Snowfall', 94: 'Freezing_Fog'\n",
    "}\n",
    "df['weather_code'] = df['weather_code'].map(weather_desc)\n",
    "\n",
    "#Map is_holiday:\n",
    "df['is_holiday'] = df['is_holiday'].map({0:'No_Holiday', 1:'Holiday'})\n",
    "\n",
    "#Map is_weekend:\n",
    "df['is_weekend'] = df['is_weekend'].map({0:'Weekday', 1:'Weekend'})\n",
    "\n",
    "#Map season:\n",
    "seasons = {0:'Spring', 1:'Summer', 2:'Fall', 3:'Winter'}\n",
    "df['season'] = df['season'].map(seasons)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Pairplot\n",
    "# sns.pairplot(df[['cnt', 't2', 'hum', 'wind_speed', 'weather_code', 'season']],\n",
    "#              hue='cnt', \n",
    "#              palette='coolwarm',\n",
    "#              height=3,\n",
    "#              aspect=1.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding for categorical variables\n",
    "df = pd.get_dummies(df, drop_first=True, dtype=int)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot to check for stationarity\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# plt.plot(y_train.to_timestamp())\n",
    "# plt.title('Hourly Bike Rentals')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is no noticeable trend in the data. The data looks stationary. Let's verify this with the Augmented Dickey-Fuller test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_stationarity(data):\n",
    "#     print('Null Hypothesis: Presence of unit root (Data is not stationary)')\n",
    "#     print('Alternate Hypothesis: Absence of unit root (Data is stationary)')\n",
    "#     result = adfuller(data, autolag='AIC')\n",
    "#     print(result)\n",
    "#     print('ADF Statistic:', result[0])\n",
    "#     print('p-value:', result[1])\n",
    "#     if result[1] > 0.05:\n",
    "#         print('Data is not stationary')\n",
    "#     else:\n",
    "#         print('Data is stationary')\n",
    "\n",
    "# #Check stationarity of the target variable\n",
    "# check_stationarity(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ACF and PACF plots\n",
    "# from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "# plt.figure(figsize=(20, 15))\n",
    "# plt.subplot(211)\n",
    "# plot_acf(y_train, lags=168, ax=plt.gca())\n",
    "# plt.subplot(212)\n",
    "# plot_pacf(y_train, lags=168, ax=plt.gca())\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimating AR terms: The PACF plot shows a significant spike at lag 1, 2, 3, 4, 5 and 6. Therefore, p = 6.\n",
    "- Estimating I term: The ADF test shows that the data is already stationary. Therefore, d = 0.\n",
    "- Estimating MA terms: The ACF plot shows a significant spike at lag 1, 2, 3, and 4. Therefore, q = 4.\n",
    "- Estimating seasonal AR terms: The PACF plot shows a significant spike at lag 24. Therefore, P = 1.\n",
    "- Estimating seasonal I term: The ADF test shows that the data is already stationary. Therefore, D = 0.\n",
    "- Estimating seasonal MA terms: The ACF plot shows a significant spike at seven 24 lag intervals. Let's start Q with 7.\n",
    "- ACF plot shows strong correlation at lag 24. This indicates a daily seasonality. Therefore, s = 24.\n",
    "\n",
    "However, running the model with these parameters is computationally expensive. For this reason, as an example, I will use small order values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training df till June 2016 and testing df from July 2016\n",
    "train_df = df.loc[:'2016-06-30']\n",
    "test_df = df.loc['2016-07-01':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "X_train = train_df.drop('cnt', axis=1)\n",
    "y_train = train_df['cnt']\n",
    "X_test = test_df.drop('cnt', axis=1)\n",
    "y_test = test_df['cnt']\n",
    "\n",
    "X_train = add_constant(X_train)\n",
    "X_test = add_constant(X_test)\n",
    "\n",
    "lr = OLS(y_train, X_train)\n",
    "lr = lr.fit()\n",
    "\n",
    "#MAE, RMSE, R2\n",
    "y_pred = lr.predict(X_test)\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n",
    "r2 = lr.rsquared\n",
    "print('MAE:', mae)\n",
    "print('RMSE:', rmse)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X_train = train_df.drop('cnt', axis=1)\n",
    "y_train = train_df['cnt']\n",
    "X_test = test_df.drop('cnt', axis=1)\n",
    "y_test = test_df['cnt']\n",
    "\n",
    "model = XGBRegressor(n_estimators=1000, max_depth=10, learning_rate=0.01, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#MAE, RMSE, R2\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n",
    "r2 = model.score(X_test, y_test)\n",
    "print('MAE:', mae)\n",
    "print('RMSE:', rmse)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prophet\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.plot import plot_cross_validation_metric\n",
    "\n",
    "pr_train = train_df.copy()\n",
    "pr_train = pr_train.reset_index()\n",
    "pr_train['timestamp'] = pr_train['timestamp'].dt.to_timestamp()\n",
    "pr_train = pr_train.rename(columns={'timestamp':'ds', 'cnt':'y'})\n",
    "\n",
    "pr_test = test_df.copy()\n",
    "pr_test = pr_test.reset_index()\n",
    "pr_test['timestamp'] = pr_test['timestamp'].dt.to_timestamp()\n",
    "pr_test = pr_test.rename(columns={'timestamp':'ds', 'cnt':'y'})\n",
    "\n",
    "\n",
    "model = Prophet()\n",
    "\n",
    "model.add_regressor('t2')\n",
    "model.add_regressor('hum')\n",
    "model.add_regressor('wind_speed')\n",
    "model.add_regressor('is_holiday_No_Holiday')\n",
    "model.add_regressor('is_weekend_Weekend')\n",
    "model.add_regressor('weather_code_Clear')\n",
    "model.add_regressor('weather_code_Cloudy')\n",
    "model.add_regressor('weather_code_Rain')\n",
    "model.add_regressor('weather_code_Scattered_Clouds')\n",
    "model.add_regressor('weather_code_Snowfall')\n",
    "model.add_regressor('season_Summer')\n",
    "model.add_regressor('season_Winter')\n",
    "\n",
    "model.fit(pr_train)\n",
    "\n",
    "#Predictions\n",
    "future = model.make_future_dataframe(periods=len(pr_test), freq='D')\n",
    "future = future.merge(pr_test[['ds', 't2', 'hum', 'wind_speed', 'is_holiday_No_Holiday', 'is_weekend_Weekend', 'weather_code_Clear', 'weather_code_Cloudy', 'weather_code_Rain', 'weather_code_Scattered_Clouds', 'weather_code_Snowfall', 'season_Summer', 'season_Winter']], on='ds', how='left')\n",
    "future.dropna(inplace=True)\n",
    "forecast = model.predict(future)\n",
    "\n",
    "#MAE, RMSE, R2\n",
    "mae = np.mean(np.abs(pr_test['y'] - forecast['yhat']))\n",
    "rmse = np.sqrt(np.mean((pr_test['y'] - forecast['yhat'])**2))\n",
    "r2 = 1 - np.sum((pr_test['y'] - forecast['yhat'])**2) / np.sum((pr_test['y'] - pr_test['y'].mean())**2)\n",
    "print('MAE:', mae)\n",
    "print('RMSE:', rmse)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train = train_df.drop('cnt', axis=1)\n",
    "y_train = train_df['cnt']\n",
    "X_test = test_df.drop('cnt', axis=1)\n",
    "y_test = test_df['cnt']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=4000, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#MAE, RMSE, R2\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n",
    "r2 = model.score(X_test, y_test)\n",
    "print('MAE:', mae)\n",
    "print('RMSE:', rmse)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data frame of pred and actual values\n",
    "pred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "#Plot of actual vs predicted values\n",
    "pred_df = pred_df.reset_index()\n",
    "fig =plt.figure(figsize=(15, 6))\n",
    "#Remove period\n",
    "pred_df['timestamp'] = pred_df['timestamp'].dt.to_timestamp()\n",
    "plt.plot(pred_df['timestamp'], pred_df['Actual'], label='Actual')\n",
    "plt.plot(pred_df['timestamp'], pred_df['Predicted'], label='Predicted')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lbs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
